{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "mat_data = scipy.io.loadmat('data/ex4data1.mat')\n",
    "mat_weights = scipy.io.loadmat('data/ex4weights.mat')\n",
    "\n",
    "X_course = mat_data['X']\n",
    "y_course = mat_data['y']\n",
    "weights_course = np.concatenate([mat_weights['Theta1'].flatten(),\n",
    "                                mat_weights['Theta2'].flatten()],\n",
    "                                axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:5000,1:]\n",
    "y = data.iloc[:5000,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = data.iloc[5002:15052, 1:]\n",
    "y_test = data.iloc[5002:15052, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "    def __init__(self, X_data, y_data, layers_size):\n",
    "        self.X = np.array(X_data, dtype = 'float32')\n",
    "        self.y = np.array([(i == y)*1 for i in model.labels]).T\n",
    "        self.labels = np.unique(y)\n",
    "        self.lsize = layers_size\n",
    "        self.net_input = None\n",
    "        self.net_output = None\n",
    "        self.net_weights_trained = None\n",
    "        \n",
    "    def AddBias(self, x, value):\n",
    "        if x.ndim > 1:\n",
    "            return np.insert(x, 0, value, axis = 1)\n",
    "        return np.insert(x, 0, value, axis = 0)\n",
    "    \n",
    "    def Sigmoid(self, z):\n",
    "        return 1/(1 + np.exp(-z))\n",
    "    \n",
    "    def SigmoidGrad(self, z):\n",
    "        return self.Sigmoid(z) * (1 - self.Sigmoid(z))\n",
    "    \n",
    "    def RandomWeights(self):\n",
    "        net_weights = []\n",
    "        for i in range(len(self.lsize)):\n",
    "            if self.lsize[i] != self.lsize[-1]:\n",
    "                eps = np.sqrt(6)/np.sqrt(self.lsize[i]\\\n",
    "                                         + self.lsize[i+1])\n",
    "                weights = np.random.rand(self.lsize[i] + 1, \n",
    "                                        self.lsize[i+1]) * 2 * eps - eps\n",
    "                net_weights.append(weights)\n",
    "        return np.concatenate([i.flatten() for i in net_weights],\n",
    "                                        axis = 0)\n",
    "    \n",
    "    def Weights(self, net_weights, layer):\n",
    "        left = 0\n",
    "        right = 0\n",
    "        for i in range(layer):\n",
    "            right += (self.lsize[i] + 1) * self.lsize[i+1]\n",
    "            if i == layer-1:\n",
    "                return (net_weights[left:right].reshape(self.lsize[i+1],\n",
    "                                                       self.lsize[i] + 1)).T\n",
    "            left += (self.lsize[i] + 1) * self.lsize[i+1]\n",
    "    \n",
    "    def ForwardPropagation(self, net_weights, X):  \n",
    "        \n",
    "        net_in = []                                                     \n",
    "        net_out = []   \n",
    "        \n",
    "        N = len(self.lsize)\n",
    "        for layer in range(N):\n",
    "            if layer == 0:\n",
    "                net_out.append(self.AddBias(X, 1))\n",
    "            else:\n",
    "                weights = self.Weights(net_weights, layer)\n",
    "                if layer == N - 1:\n",
    "                    z = np.matmul(net_out[-1], weights)\n",
    "                    net_out.append(self.Sigmoid(z))\n",
    "                else:\n",
    "                    z = np.matmul(net_out[-1], weights)\n",
    "                    net_in.append(z)\n",
    "                    net_out.append(self.AddBias(self.Sigmoid(z), 1))\n",
    "                    \n",
    "        self.net_input = net_in\n",
    "        self.net_output = net_out\n",
    "    \n",
    "    def CostFunction(self, net_weights, X, y, lmbda):\n",
    "        \n",
    "        self.ForwardPropagation(net_weights, X)\n",
    "        \n",
    "        m = X.shape[0] \n",
    "        \n",
    "        nonreg_term = np.sum(-y * np.log(self.net_output[-1]) - (1 - y)\\\n",
    "                             * np.log(1 - self.net_output[-1]))/m\n",
    "        weights_sq = np.sum(self.Weights(net_weights, layer)[:,1:]**2)\n",
    "                                   for layer in range(1, len(self.lsize))\n",
    "        reg_term = lmbda * np.sum(weights_sq)/(2*m)\n",
    "        return nonreg_term + reg_term\n",
    "    \n",
    "    def BackwardPropagation(self, net_weights, X, y, lmbda):\n",
    "        net_delta = []\n",
    "        net_grad = []\n",
    "        \n",
    "        m = X.shape[0] \n",
    "        \n",
    "        N = len(self.lsize)\n",
    "        for layer in range(N-1, 0, -1):\n",
    "            if layer == N - 1:\n",
    "                delta = self.net_output[layer] - y\n",
    "            elif layer != 0:\n",
    "                weights = self.Weights(net_weights, layer+1)\n",
    "                layer_input = self.net_input[layer+1]\n",
    "                grad = self.SigmoidGrad(layer_input)\n",
    "                delta = np.matmul(delta, weights.T[:,1:]) * grad\n",
    "            net_delta.append(delta)\n",
    "            \n",
    "            reg_weights = self.AddBias(self.Weights(net_weights, \n",
    "                                                    layer)[:,1:], 0)\n",
    "            layer_output = self.net_output[layer-1]\n",
    "            reg_term = lmbda/m * reg_weights\n",
    "            net_grad.insert(0, np.matmul(delta.T, layer_output))\n",
    "        \n",
    "        return np.concatenate([i.flatten() for i in net_grad], axis = 0)\n",
    "        \n",
    "        \n",
    "#     def Fit(self, lmbda):\n",
    "#         random_weights = self.RandomWeights()\n",
    "#         random_weights = np.concatenate([i.flatten() for i in random_weights],\n",
    "#                                         axis = 0)\n",
    "#         args_ = (self.X, self.y, lmbda)\n",
    "#         res = minimize(fun = self.CostFunction, args = args_, \n",
    "#                        x0=random_weights, method = 'TNC',\n",
    "#                        jac = self.BackwardPropagation)\n",
    "        \n",
    "#         self.net_weights_trained = res.x\n",
    "#         print(res)\n",
    "        \n",
    "#     def Predict(self, x, y):\n",
    "#         x = np.array(x, dtype = 'float32')\n",
    "#         self.ForwardPropagation(self.net_weights_trained, x)\n",
    "#         pred_mat = self.net_output[-1]\n",
    "#         ids_of_max = np.argmax(pred_mat, axis = 1)\n",
    "#         pred = np.array([self.labels[i] for i in ids_of_max]) \n",
    "#         print(pred)     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
